
  <!DOCTYPE html>
  <html>
    <head>
      <title>AWSS3UploadTask.ts</title>
      <link href="https://cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css" type="text/css" rel="stylesheet">
      <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.58.2/codemirror.min.js" type="text/javascript" charset="utf-8"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.58.2/mode/javascript/javascript.min.js" type="text/javascript" charset="utf-8"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.58.2/codemirror.min.css" type="text/css" rel="stylesheet">
<script src="../../../assets/source-file.js" type="text/javascript" charset="utf-8"></script>
<link href="../../../assets/source-file.css" type="text/css" rel="stylesheet">
    </head>
    <body>
    <div style="margin-top:3em" class="ui container"><h1 class="ui header"><a href="../../../index.html">TypeScript coverage report</a></h1><table style="margin-top:2em" class="ui celled table"><thead class=""><tr class=""><th class="">Filename</th><th class="">Percent</th><th class="">Threshold</th><th class="">Total</th><th class="">Covered</th><th class="">Uncovered</th></tr></thead><tbody class=""><tr class="positive"><td class="">src/providers/AWSS3UploadTask.ts</td><td class="">98.46%</td><td class="">0%</td><td class="">907</td><td class="">893</td><td class="">14</td></tr></tbody></table><textarea id="editor" readonly="" style="margin-top:3em">import {
	UploadPartCommandInput,
	CompletedPart,
	S3Client,
	UploadPartCommand,
	CompleteMultipartUploadCommand,
	Part,
	AbortMultipartUploadCommand,
	ListPartsCommand,
	CreateMultipartUploadCommand,
	PutObjectCommandInput,
	ListObjectsV2Command,
} from &#x27;@aws-sdk/client-s3&#x27;;
import * as events from &#x27;events&#x27;;
import axios, { Canceler, CancelTokenSource } from &#x27;axios&#x27;;
import { HttpHandlerOptions } from &#x27;@aws-sdk/types&#x27;;
import { Logger } from &#x27;@aws-amplify/core&#x27;;
import { UploadTask } from &#x27;../types/Provider&#x27;;
import { byteLength, isFile } from &#x27;../common/StorageUtils&#x27;;
import { AWSS3ProviderUploadErrorStrings } from &#x27;../common/StorageErrorStrings&#x27;;
import {
	SET_CONTENT_LENGTH_HEADER,
	UPLOADS_STORAGE_KEY,
} from &#x27;../common/StorageConstants&#x27;;
import { StorageAccessLevel } from &#x27;..&#x27;;

const logger = new Logger(&#x27;AWSS3UploadTask&#x27;);
export enum AWSS3UploadTaskState {
	INIT,
	IN_PROGRESS,
	PAUSED,
	CANCELLED,
	COMPLETED,
}

export enum TaskEvents {
	CANCEL = &#x27;cancel&#x27;,
	UPLOAD_COMPLETE = &#x27;uploadComplete&#x27;,
	UPLOAD_PROGRESS = &#x27;uploadPartProgress&#x27;,
	ERROR = &#x27;error&#x27;,
}

export interface AWSS3UploadTaskParams {
	s3Client: S3Client;
	file: Blob;
	storage: Storage;
	level: StorageAccessLevel;
	params: PutObjectCommandInput;
	prefixPromise: Promise&lt;string&gt;;
	emitter?: events.EventEmitter;
}

export interface InProgressRequest {
	uploadPartInput: UploadPartCommandInput;
	s3Request: Promise&lt;any&gt;;
	cancel: Canceler;
}

export interface UploadTaskCompleteEvent {
	key: string;
}

export interface UploadTaskProgressEvent {
	/**
	 * bytes that has been sent to S3 so far
	 */
	loaded: number;
	/**
	 * total bytes that needs to be sent to S3
	 */
	total: number;
}

export interface FileMetadata {
	bucket: string;
	fileName: string;
	key: string;
	// Unix timestamp in ms
	lastTouched: number;
	uploadId: string;
}

// maximum number of parts per upload request according the S3 spec,
// see: https://docs.aws.amazon.com/AmazonS3/latest/userguide/qfacts.html
const MAX_PARTS = 10000;
// 5MB in bytes
const PART_SIZE = 5 * 1024 * 1024;
const DEFAULT_QUEUE_SIZE = 4;

function comparePartNumber(a: CompletedPart, b: CompletedPart) {
	return a.PartNumber - b.PartNumber;
}

export class AWSS3UploadTask implements UploadTask {
	private readonly emitter: events.EventEmitter;
	private readonly file: Blob;
	private readonly partSize: number = PART_SIZE;
	private readonly queueSize = DEFAULT_QUEUE_SIZE;
	private readonly s3client: S3Client;
	private readonly storage: Storage;
	private readonly storageSync: Promise&lt;any&gt;;
	private readonly fileId: string;
	private readonly params: PutObjectCommandInput;
	private readonly prefixPromise: Promise&lt;string&gt;;
	private inProgress: InProgressRequest[] = [];
	private completedParts: CompletedPart[] = [];
	private queued: UploadPartCommandInput[] = [];
	private bytesUploaded: number = 0;
	private totalBytes: number = 0;
	private uploadId: string;

	public state: AWSS3UploadTaskState = AWSS3UploadTaskState.INIT;

	constructor({
		s3Client,
		file,
		emitter,
		storage,
		params,
		level,
		prefixPromise,
	}: AWSS3UploadTaskParams) {
		this.prefixPromise = prefixPromise;
		this.s3client = s3Client;
		this.s3client.middlewareStack.remove(SET_CONTENT_LENGTH_HEADER);
		this.storage = storage;
		this.storageSync = Promise.resolve();
		if (typeof this.storage[&#x27;sync&#x27;] === &#x27;function&#x27;) {
			this.storageSync = this.storage[&#x27;sync&#x27;]();
		}
		this.params = params;
		this.file = file;
		this.totalBytes = this.file.size;
		this.bytesUploaded = 0;
		this.emitter = emitter;
		this.queued = [];
		this.fileId = this._getFileId(level);
		this._validateParams();
		// event emitter will re-throw an error if an event emits an error unless there&#x27;s a listener, attaching a no-op
		// function to it unless user adds their own onError callback
		this.emitter.on(TaskEvents.ERROR, () =&gt; {});
	}

	get percent() {
		return (this.bytesUploaded / this.totalBytes) * 100;
	}

	get isInProgress() {
		return this.state === AWSS3UploadTaskState.IN_PROGRESS;
	}

	private async _listSingleFile({
		key,
		bucket,
	}: {
		key: string;
		bucket: string;
	}) {
		const listObjectRes = await this.s3client.send(
			new ListObjectsV2Command({
				Bucket: bucket,
				Prefix: key,
			})
		);
		const { Contents = [] } = listObjectRes;
		const prefix = await this.prefixPromise;
		const obj = Contents.find(o =&gt; o.Key === `${prefix}${key}`);
		return obj;
	}

	private _getFileId(level: StorageAccessLevel): string {
		// We should check if it&#x27;s a File first because File is also instance of a Blob
		if (isFile(this.file)) {
			return [
				this.file.name,
				this.file.lastModified,
				this.file.size,
				this.file.type,
				this.params.Bucket,
				level,
				this.params.Key,
			].join(&#x27;-&#x27;);
		} else {
			return [
				this.file.size,
				this.file.type,
				this.params.Bucket,
				level,
				this.params.Key,
			].join(&#x27;-&#x27;);
		}
	}

	private async _findCachedUploadParts(): Promise&lt;{
		parts: Part[];
		uploadId: string;
	}&gt; {
		const uploadRequests = await this._listCachedUploadTasks();

		if (
			Object.keys(uploadRequests).length === 0 ||
			!Object.prototype.hasOwnProperty.call(uploadRequests, this.fileId)
		) {
			return { parts: [], uploadId: null };
		}

		const cachedUploadFileData = uploadRequests[this.fileId];
		cachedUploadFileData.lastTouched = Date.now();
		this.storage.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(uploadRequests));

		const listPartsOutput = await this.s3client.send(
			new ListPartsCommand({
				Bucket: this.params.Bucket,
				Key: this.params.Key,
				UploadId: cachedUploadFileData.uploadId,
			})
		);

		return {
			parts: listPartsOutput.Parts || [],
			uploadId: cachedUploadFileData.uploadId,
		};
	}

	private _emitEvent&lt;T = any&gt;(event: string, payload: T) {
		this.emitter.emit(event, payload);
	}

	private _validateParams() {
		if (this.file.size / this.partSize &gt; MAX_PARTS) {
			throw new Error(
				`Too many parts. Number of parts is ${this.file.size /
					this.partSize}, maximum is ${MAX_PARTS}.`
			);
		}
	}

	private async _listCachedUploadTasks(): Promise&lt;
		Record&lt;string, FileMetadata&gt;
	&gt; {
		await this.storageSync;
		const tasks = this.storage.getItem(UPLOADS_STORAGE_KEY) || &#x27;{}&#x27;;
		return JSON.parse(tasks);
	}

	private async _cache(fileMetadata: FileMetadata): Promise&lt;void&gt; {
		const uploadRequests = await this._listCachedUploadTasks();
		uploadRequests[this.fileId] = fileMetadata;
		this.storage.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(uploadRequests));
	}

	private async _isCached(): Promise&lt;boolean&gt; {
		return Object.prototype.hasOwnProperty.call(
			await this._listCachedUploadTasks(),
			this.fileId
		);
	}

	private async _removeFromCache(): Promise&lt;void&gt; {
		const uploadRequests = await this._listCachedUploadTasks();
		delete uploadRequests[this.fileId];
		this.storage.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(uploadRequests));
	}

	private async _onPartUploadCompletion({
		eTag,
		partNumber,
		chunk,
	}: {
		eTag: string;
		partNumber: number;
		chunk: UploadPartCommandInput[&#x27;Body&#x27;];
	}) {
		this.completedParts.push({
			ETag: eTag,
			PartNumber: partNumber,
		});
		this.bytesUploaded += byteLength(chunk);
		this._emitEvent&lt;UploadTaskProgressEvent&gt;(TaskEvents.UPLOAD_PROGRESS, {
			loaded: this.bytesUploaded,
			total: this.totalBytes,
		});
		// Remove the completed item from the inProgress array
		this.inProgress = this.inProgress.filter(
			job =&gt; job.uploadPartInput.PartNumber !== partNumber
		);
		if (this.queued.length &amp;&amp; this.state !== AWSS3UploadTaskState.PAUSED)
			this._startNextPart();
		if (this._isDone()) this._completeUpload();
	}

	private async _completeUpload() {
		try {
			await this.s3client.send(
				new CompleteMultipartUploadCommand({
					Bucket: this.params.Bucket,
					Key: this.params.Key,
					UploadId: this.uploadId,
					MultipartUpload: {
						// Parts are not always completed in order, we need to manually sort them
						Parts: this.completedParts.sort(comparePartNumber),
					},
				})
			);
			this._verifyFileSize();
			this._emitEvent&lt;UploadTaskCompleteEvent&gt;(TaskEvents.UPLOAD_COMPLETE, {
				key: `${this.params.Bucket}/${this.params.Key}`,
			});
			this._removeFromCache();
			this.state = AWSS3UploadTaskState.COMPLETED;
		} catch (err) {
			logger.error(&#x27;error completing upload&#x27;, err);
			this._emitEvent(TaskEvents.ERROR, err);
		}
	}

	private async _makeUploadPartRequest(
		input: UploadPartCommandInput,
		cancelTokenSource: CancelTokenSource
	) {
		try {
			const res = await this.s3client.send(new UploadPartCommand(input), {
				cancelTokenSource,
			} as HttpHandlerOptions);
			await this._onPartUploadCompletion({
				eTag: res.ETag,
				partNumber: input.PartNumber,
				chunk: input.Body,
			});
		} catch (err) {
			if (this.state === AWSS3UploadTaskState.PAUSED) {
				logger.log(&#x27;upload paused&#x27;);
			} else if (this.state === AWSS3UploadTaskState.CANCELLED) {
				logger.log(&#x27;upload aborted&#x27;);
			} else {
				logger.error(&#x27;error starting next part of upload: &#x27;, err);
			}
			// axios&#x27; cancel will also throw an error, however we don&#x27;t need to emit an event in that case as it&#x27;s an
			// expected behavior
			if (
				!axios.isCancel(err) &amp;&amp;
				err.message !== AWSS3ProviderUploadErrorStrings.UPLOAD_PAUSED_MESSAGE
			) {
				this._emitEvent(TaskEvents.ERROR, err);
				this.pause();
			}
		}
	}

	private _startNextPart() {
		if (this.queued.length &gt; 0 &amp;&amp; this.state !== AWSS3UploadTaskState.PAUSED) {
			const cancelTokenSource = axios.CancelToken.source();
			const nextPart = this.queued.shift();
			this.inProgress.push({
				uploadPartInput: nextPart,
				s3Request: this._makeUploadPartRequest(nextPart, cancelTokenSource),
				cancel: cancelTokenSource.cancel,
			});
		}
	}

	/**
	 * Verify on S3 side that the file size matches the one on the client side.
	 *
	 * @async
	 * @throws throws an error if the file size does not match between local copy of the file and the file on s3.
	 */
	private async _verifyFileSize() {
		const obj = await this._listSingleFile({
			key: this.params.Key,
			bucket: this.params.Bucket,
		});
		const valid = Boolean(obj &amp;&amp; obj.Size === this.file.size);
		if (!valid) {
			throw new Error(
				&#x27;File size does not match between local file and file on s3&#x27;
			);
		}
		return valid;
	}

	private _isDone() {
		return (
			!this.queued.length &amp;&amp;
			!this.inProgress.length &amp;&amp;
			this.bytesUploaded === this.totalBytes
		);
	}

	private _createParts() {
		const size = this.file.size;
		const parts: UploadPartCommandInput[] = [];
		for (let bodyStart = 0; bodyStart &lt; size; ) {
			const bodyEnd = Math.min(bodyStart + this.partSize, size);
			parts.push({
				Body: this.file.slice(bodyStart, bodyEnd),
				Key: this.params.Key,
				Bucket: this.params.Bucket,
				PartNumber: parts.length + 1,
				UploadId: this.uploadId,
			});
			bodyStart += this.partSize;
		}
		return parts;
	}

	private _initCachedUploadParts(cachedParts: Part[]) {
		this.bytesUploaded += cachedParts.reduce((acc, part) =&gt; acc + part.Size, 0);
		// Find the set of part numbers that have already been uploaded
		const uploadedPartNumSet = new Set(
			cachedParts.map(part =&gt; part.PartNumber)
		);
		this.queued = this.queued.filter(
			part =&gt; !uploadedPartNumSet.has(part.PartNumber)
		);
		this.completedParts = cachedParts.map(part =&gt; ({
			PartNumber: part.PartNumber,
			ETag: part.ETag,
		}));
		this._emitEvent&lt;UploadTaskProgressEvent&gt;(TaskEvents.UPLOAD_PROGRESS, {
			loaded: this.bytesUploaded,
			total: this.totalBytes,
		});
	}

	private async _initMultipartUpload() {
		const res = await this.s3client.send(
			new CreateMultipartUploadCommand(this.params)
		);
		this._cache({
			uploadId: res.UploadId,
			lastTouched: Date.now(),
			bucket: this.params.Bucket,
			key: this.params.Key,
			fileName: this.file instanceof File ? this.file.name : &#x27;&#x27;,
		});
		return res.UploadId;
	}

	private async _initializeUploadTask() {
		this.state = AWSS3UploadTaskState.IN_PROGRESS;
		try {
			if (await this._isCached()) {
				const { parts, uploadId } = await this._findCachedUploadParts();
				this.uploadId = uploadId;
				this.queued = this._createParts();
				this._initCachedUploadParts(parts);
				this._startUpload();
			} else {
				if (!this.uploadId) {
					const uploadId = await this._initMultipartUpload();
					this.uploadId = uploadId;
					this.queued = this._createParts();
					this._startUpload();
				}
			}
		} catch (err) {
			if (!axios.isCancel(err)) {
				logger.error(&#x27;Error initializing the upload task&#x27;, err);
			}
		}
	}

	public resume(): void {
		if (this.state === AWSS3UploadTaskState.CANCELLED) {
			logger.warn(&#x27;This task has already been cancelled&#x27;);
		} else if (this.state === AWSS3UploadTaskState.COMPLETED) {
			logger.warn(&#x27;This task has already been completed&#x27;);
		} else if (this.state === AWSS3UploadTaskState.IN_PROGRESS) {
			logger.warn(&#x27;Upload task already in progress&#x27;);
			// first time running resume, find any cached parts on s3 or start a new multipart upload request before
			// starting the upload
		} else if (!this.uploadId) {
			this._initializeUploadTask();
		} else {
			this._startUpload();
		}
	}

	private _startUpload() {
		this.state = AWSS3UploadTaskState.IN_PROGRESS;
		for (let i = 0; i &lt; this.queueSize; i++) {
			this._startNextPart();
		}
	}

	async _cancel(): Promise&lt;boolean&gt; {
		if (this.state === AWSS3UploadTaskState.CANCELLED) {
			logger.warn(&#x27;This task has already been cancelled&#x27;);
			return false;
		} else if (this.state === AWSS3UploadTaskState.COMPLETED) {
			logger.warn(&#x27;This task has already been completed&#x27;);
			return false;
		} else {
			this.pause();
			this.queued = [];
			this.completedParts = [];
			this.bytesUploaded = 0;
			this.state = AWSS3UploadTaskState.CANCELLED;
			try {
				await this.s3client.send(
					new AbortMultipartUploadCommand({
						Bucket: this.params.Bucket,
						Key: this.params.Key,
						UploadId: this.uploadId,
					})
				);
				await this._removeFromCache();
				return true;
			} catch (err) {
				logger.error(&#x27;Error cancelling upload task&#x27;, err);
				return false;
			}
		}
	}

	/**
	 * pause this particular upload task
	 **/
	public pause(): void {
		if (this.state === AWSS3UploadTaskState.CANCELLED) {
			logger.warn(&#x27;This task has already been cancelled&#x27;);
		} else if (this.state === AWSS3UploadTaskState.COMPLETED) {
			logger.warn(&#x27;This task has already been completed&#x27;);
		} else if (this.state === AWSS3UploadTaskState.PAUSED) {
			logger.warn(&#x27;This task is already paused&#x27;);
		}
		this.state = AWSS3UploadTaskState.PAUSED;
		// Use axios cancel token to abort the part request immediately
		// Add the inProgress parts back to pending
		const removedInProgressReq = this.inProgress.splice(
			0,
			this.inProgress.length
		);
		removedInProgressReq.forEach(req =&gt; {
			req.cancel(AWSS3ProviderUploadErrorStrings.UPLOAD_PAUSED_MESSAGE);
		});
		// Put all removed in progress parts back into the queue
		this.queued.unshift(
			...removedInProgressReq.map(req =&gt; req.uploadPartInput)
		);
	}
}
</textarea><pre id="annotations" style="display:none">[{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:311,&quot;character&quot;:43,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:312,&quot;character&quot;:37,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:310,&quot;character&quot;:11,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:335,&quot;character&quot;:57,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:340,&quot;character&quot;:20,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:341,&quot;character&quot;:4,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:341,&quot;character&quot;:8,&quot;text&quot;:&quot;message&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:343,&quot;character&quot;:38,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:329,&quot;character&quot;:11,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:457,&quot;character&quot;:23,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:458,&quot;character&quot;:55,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:456,&quot;character&quot;:11,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:510,&quot;character&quot;:49,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1},{&quot;file&quot;:&quot;src/providers/AWSS3UploadTask.ts&quot;,&quot;line&quot;:509,&quot;character&quot;:12,&quot;text&quot;:&quot;err&quot;,&quot;kind&quot;:1}]</pre></div>
    <p class="footer-text">TypeScript Coverage Report generated by <a href="https://github.com/plantain-00/type-coverage">type-coverage</a> and <a href="https://github.com/alexcanessa/typescript-coverage-report">typescript-coverage-report</a> at Mon, 17 Oct 2022 20:15:23 GMT</p>
    </body>
  </html>
  